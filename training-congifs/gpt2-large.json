{
  "attn_pdrop" : 0.1,
  "embd_pdrop" : 0.1,
  "initializer_range" : 0.02,
  "layer_norm_epsilon" : 1e-05,
  "model_type" : "gpt2",
  "n_ctx" : 1024,
  "n_embd" : 1280,
  "n_head" : 20,
  "n_layer" : 36,
  "n_positions" : 1024,
  "resid_pdrop" : 0.1,
  "summary_activation" : null,
  "summary_first_dropout" : 0.1,
  "summary_proj_to_labels" : true,
  "summary_type" : "cls_index",
  "summary_use_proj" : true,
  "task_specific_params": {
    "text-generation" : {
      "do_sample": true,
      "max_length": 50
    }
  }
}